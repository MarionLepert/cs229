{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PLOTTING\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('notebook', font_scale=1.5)\n",
    "import matplotlib.gridspec\n",
    "import collections\n",
    "import os\n",
    "import math\n",
    "\n",
    "# PYTORCH \n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from models import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetFromFile import MidiSavedDataset\n",
    "midi_train_dataset = MidiSavedDataset(data_type = \"train\")\n",
    "midi_val_dataset   = MidiSavedDataset(data_type = \"val\")\n",
    "midi_test_dataset  = MidiSavedDataset(data_type = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(midi_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(midi_train_dataset, batch_size=256,\n",
    "                        shuffle=True, num_workers=6)\n",
    "valloader   = DataLoader(midi_val_dataset, batch_size=256,\n",
    "                        shuffle=True, num_workers=6)\n",
    "testloader  = DataLoader(midi_test_dataset, batch_size=256,\n",
    "                        shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(preds, labels): \n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    num_true_pos_label  = 0.0\n",
    "    num_false_pos_label = 0.0\n",
    "    num_pos_pred  = 0.0\n",
    "    num_true_neg_label  = 0.0\n",
    "    num_false_neg_label = 0.0\n",
    "    num_neg_pred  = 0.0\n",
    "\n",
    "    num_timesteps = labels.shape[0]\n",
    "\n",
    "    for i in range(num_timesteps): \n",
    "        for j in range(num_notes):\n",
    "            if (labels[i,j] == 1.0):\n",
    "                num_pos_pred += 1.0\n",
    "            else: \n",
    "                num_neg_pred += 1.0\n",
    "\n",
    "            if (preds[i,j] == labels[i,j]): \n",
    "                if (preds[i,j] == 1.0):\n",
    "                    num_true_pos_label += 1.0\n",
    "                else: \n",
    "                    num_true_neg_label += 1.0\n",
    "                correct += 1.0\n",
    "            else: \n",
    "                if (preds[i,j] == 1.0): \n",
    "                    num_false_pos_label += 1.0\n",
    "                else: \n",
    "                    num_false_neg_label += 1.0\n",
    "            total += 1.0\n",
    "            \n",
    "    accuracy = correct/total \n",
    "    recall = num_true_pos_label / num_pos_pred\n",
    "    if (num_true_pos_label == 0 and num_false_pos_label == 0): \n",
    "        precision = 1\n",
    "    else: \n",
    "        precision = num_true_pos_label/ (num_true_pos_label + num_false_pos_label)\n",
    "    \n",
    "    print(\"Correct: \", correct, \", Num pos: \", num_pos_pred, \"num true pos: \", num_true_pos_label, \"num false pos: \", num_false_pos_label, \", accuracy: \", accuracy, \", recall: \", recall)\n",
    "    \n",
    "    return accuracy, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e272ff48817a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtest_loss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs229/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mN1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mF1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "pos_weight_train_loss_list = []\n",
    "pos_weight_val_loss_list = []\n",
    "pos_weight_test_loss_list = []\n",
    "\n",
    "\n",
    "pos_weight_val_preds_list  = []\n",
    "pos_weight_val_labels_list = []\n",
    "pos_weight_test_preds_list = []\n",
    "pos_weight_test_labels_list = []\n",
    "\n",
    "\n",
    "list_pos_weight = [0.1, 1.0, 10.0, 50.0]\n",
    "\n",
    "val_preds_list  = []\n",
    "val_labels_list = []\n",
    "\n",
    "test_preds_list = []\n",
    "test_labels_list = []\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list   = []\n",
    "test_loss_list = []\n",
    "\n",
    "num_notes = 129\n",
    "\n",
    "for pos_weight in list_pos_weight: \n",
    "    val_preds_list  = []\n",
    "    val_labels_list = []\n",
    "    test_preds_list = []\n",
    "    test_labels_list = []\n",
    "    train_loss_list = []\n",
    "    val_loss_list   = []\n",
    "    test_loss_list = []\n",
    "\n",
    "    net = Net().cuda().double()\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight = torch.FloatTensor([pos_weight])).cuda()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=1.0, momentum=0.9)\n",
    "\n",
    "    for epoch in range(4):  # loop over the dataset multiple times\n",
    "\n",
    "        # TRAIN \n",
    "        train_labels = np.zeros((len(trainloader.dataset), num_notes))\n",
    "        train_preds  = np.zeros((len(trainloader.dataset), num_notes))\n",
    "        idx = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            #get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs.double())\n",
    "            loss = criterion(outputs, labels.double())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_labels[idx:idx+labels.shape[0], :] = labels.cpu().detach().numpy()\n",
    "            train_preds[idx:idx+labels.shape[0], :]  = sigmoid(outputs.cpu().detach()).numpy()\n",
    "\n",
    "            idx = idx + labels.shape[0]\n",
    "            print(\"Iter: \", i, \", Loss: \", loss.item())\n",
    "\n",
    "            # Get loss \n",
    "            train_loss_list.append(loss.item())\n",
    "\n",
    "#        # VALIDATE\n",
    "#             sum_val_loss = 0\n",
    "#             val_labels = np.zeros((len(valloader.dataset), num_notes))\n",
    "#             val_preds  = np.zeros((len(valloader.dataset), num_notes))\n",
    "#             idx = 0\n",
    "#             with torch.no_grad():\n",
    "#                 for i, data in enumerate(valloader,0):\n",
    "#                     inputs, labels = data\n",
    "#                     inputs = inputs.cuda()\n",
    "#                     labels = labels.cuda()\n",
    "#                     outputs = net(inputs.double())\n",
    "\n",
    "#                     loss = criterion(outputs, labels.double())\n",
    "\n",
    "#                     sum_val_loss += loss.item()\n",
    "\n",
    "#                     val_labels[idx:idx+labels.shape[0], :] = labels.cpu().detach().numpy()\n",
    "#                     val_preds[idx:idx+labels.shape[0], :]  = sigmoid(outputs.cpu().detach()).numpy()\n",
    "\n",
    "#                     val_labels_list.append(val_labels)\n",
    "#                     val_preds_list.append(val_preds)\n",
    "#                     idx = idx + labels.shape[0]\n",
    "#             # Loss \n",
    "#             avg_val_loss = sum_val_loss / len(valloader)\n",
    "#             val_loss_list.append(avg_val_loss)\n",
    "#         print(\"Epoch: \", epoch)\n",
    "        \n",
    "        # TEST\n",
    "            sum_test_loss = 0\n",
    "            test_labels = np.zeros((len(testloader.dataset), num_notes))\n",
    "            test_preds  = np.zeros((len(testloader.dataset), num_notes))\n",
    "            idx = 0\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(testloader,0):\n",
    "                    inputs, labels = data\n",
    "                    inputs = inputs.cuda()\n",
    "                    labels = labels.cuda()\n",
    "                    outputs = net(inputs.double())\n",
    "\n",
    "                    loss = criterion(outputs, labels.double())\n",
    "\n",
    "                    sum_test_loss += loss.item()\n",
    "\n",
    "                    test_labels[idx:idx+labels.shape[0], :] = labels.cpu().detach().numpy()\n",
    "                    test_preds[idx:idx+labels.shape[0], :]  = sigmoid(outputs.cpu().detach()).numpy()\n",
    "\n",
    "                    test_labels_list.append(test_labels)\n",
    "                    test_preds_list.append(test_preds)\n",
    "                    idx = idx + labels.shape[0]\n",
    "            # Loss \n",
    "            avg_test_loss = sum_test_loss / len(testloader)\n",
    "            test_loss_list.append(avg_test_loss)\n",
    "            \n",
    "            \n",
    "\n",
    "        print(\"Epoch: \", epoch)\n",
    "\n",
    "    pos_weight_test_preds_list.append(test_preds_list)\n",
    "    pos_weight_test_labels_list.append(test_labels_list)\n",
    "    \n",
    "    pos_weight_train_loss_list.append(train_loss_list)\n",
    "    pos_weight_test_loss_list.append(test_loss_list)\n",
    "\n",
    "    \n",
    "    print('Finished Training with pos weight: ', pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './midi_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_pos_weight = len(pos_weight_train_loss_list)\n",
    "\n",
    "# for j in range(1): \n",
    "#     pos_weight_val_preds_list[j]  = np.vstack(pos_weight_val_preds_list[j])\n",
    "#     pos_weight_val_labels_list[j] = np.vstack(pos_weight_val_labels_list[j])\n",
    "    \n",
    "# n_classes = pos_weight_val_preds_list[0].shape[1]\n",
    "\n",
    "# pos_weight_labels = ['0.1', '1.0', '200.0']\n",
    "\n",
    "n_pos_weight = len(pos_weight_test_loss_list)\n",
    "\n",
    "for j in range(n_pos_weight): \n",
    "    pos_weight_test_preds_list[j]  = np.vstack(pos_weight_test_preds_list[j])\n",
    "    pos_weight_test_labels_list[j] = np.vstack(pos_weight_test_labels_list[j])\n",
    "    \n",
    "n_classes = pos_weight_test_preds_list[0].shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(num=None, figsize=(15, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.xlabel('Batch iterations', fontsize=30)\n",
    "plt.ylabel('Loss', fontsize=30)\n",
    "\n",
    "plt.plot(train_loss_list, label='Train', linewidth=2)\n",
    "plt.plot(test_loss_list,   label='Val', linewidth=2)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(num=None, figsize=(15, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.xlabel('Batch iterations', fontsize=30)\n",
    "plt.ylabel('Loss', fontsize=30)\n",
    "\n",
    "n_pos_weight = len(pos_weight_train_loss_list)\n",
    "color=iter(cm.rainbow(np.linspace(0,1,n_pos_weight)))\n",
    "for j in range(n_pos_weight):\n",
    "    c=next(color)\n",
    "    pos_weight = list_pos_weight[j]\n",
    "    plt.plot(pos_weight_train_loss_list[j], c=c, label='Train, Pos Weight: ' + str(pos_weight), linewidth=2)\n",
    "    plt.plot(pos_weight_test_loss_list[j],   c=c, linestyle='--',label='Test,   Pos Weight: ' + str(pos_weight), linewidth=2)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_preds_array = np.vstack(val_preds_list)\n",
    "# val_labels_array = np.vstack(val_labels_list)\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import math\n",
    "\n",
    "pos_weight_labels = ['1.0']\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.xlabel('Recall',fontsize=30)\n",
    "plt.ylabel('Precision',fontsize=30)\n",
    "plt.ylim([0.0, 0.2])\n",
    "plt.xlim([0.0, 1.0])\n",
    "\n",
    "for j in range(n_pos_weight): \n",
    "    # For each class\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(pos_weight_test_labels_list[j][:, i],\n",
    "                                                            pos_weight_test_preds_list[j][:, i])\n",
    "        average_precision[i] = average_precision_score(pos_weight_test_labels_list[j][:, i], pos_weight_test_preds_list[j][:, i])\n",
    "\n",
    "    # A \"micro-average\": quantifying score on all classes jointly\n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(pos_weight_test_labels_list[j].ravel(),\n",
    "        pos_weight_test_preds_list[j].ravel())\n",
    "    average_precision[\"micro\"] = average_precision_score(pos_weight_test_labels_list[j], pos_weight_test_preds_list[j] ,\n",
    "                                                         average=\"micro\")\n",
    "    print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n",
    "          .format(average_precision[\"micro\"]))\n",
    "\n",
    "\n",
    "    plt.step(recall['micro'], precision['micro'], where='post', label = pos_weight_labels[j], linewidth = 2)\n",
    "\n",
    "# plt.title(\n",
    "#     'Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n",
    "#     .format(average_precision[\"micro\"]))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=30)\n",
    "plt.ylabel('True Positive Rate', fontsize=30)\n",
    "    \n",
    "for j in range(n_pos_weight):\n",
    "    test_preds_array  = np.vstack(pos_weight_test_preds_list[j])\n",
    "    test_labels_array = np.vstack(pos_weight_test_labels_list[j])\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(test_labels_array[:, i], test_preds_array[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_labels_array.ravel(), test_preds_array.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "    \n",
    "    # Plot all ROC curves\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='Pos weight: ' + pos_weight_labels[j] + '/ micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]), linewidth=4)\n",
    "    \n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
